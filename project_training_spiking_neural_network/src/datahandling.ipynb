{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Feb 11 08:08:10 2020\n",
    "\n",
    "@author: ma3352bo\n",
    "\"\"\"\n",
    "\n",
    "import os.path\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from re import findall\n",
    "import glob\n",
    "\n",
    "try:\n",
    "   import cPickle as pickle\n",
    "except:\n",
    "   import pickle\n",
    "from struct import unpack\n",
    "\n",
    "file_dir = os.path.dirname(__file__)\n",
    "sys.path.append(file_dir)\n",
    "\n",
    "def get_MNIST_data(picklename, MNIST_data_path, bTrain = True):\n",
    "    \"\"\"Efficient data retrieval\n",
    "       First time it resaves the data in pickle-format \n",
    "       which is much faster to retrieve the next time\n",
    "       \n",
    "       Returns data dictionary\n",
    "       data['x'] = image data\n",
    "       data['y'] = image labels\n",
    "       data['cols'] = number of columns\n",
    "       data['rows'] = number of rows\n",
    "       \n",
    "    \"\"\"\n",
    "  \n",
    "    picklename = '%s.pickle' % picklename\n",
    "        \n",
    "    path = Path(os.path.dirname(__file__) )\n",
    "    path = path / MNIST_data_path    \n",
    "    \n",
    "    pn = path / picklename # full path for pickle file\n",
    "    \n",
    "    if pn.exists():\n",
    "        data = pickle.load(open(pn,'rb'))\n",
    "    else:\n",
    "        # Open the images with gzip in read binary mode    \n",
    "        if bTrain:\n",
    "            images = open(path / 'train-images-idx3-ubyte','rb')\n",
    "            labels = open(path / 'train-labels-idx1-ubyte','rb')\n",
    "        else:\n",
    "            images = open(path / 't10k-images-idx3-ubyte','rb')\n",
    "            labels = open(path / 't10k-labels-idx1-ubyte','rb')\n",
    "        # Get metadata for images\n",
    "        images.read(4)  # skip the magic_number\n",
    "        number_of_images = unpack('>I', images.read(4))[0]\n",
    "        rows = unpack('>I', images.read(4))[0]\n",
    "        cols = unpack('>I', images.read(4))[0]\n",
    "        # Get metadata for labels\n",
    "        labels.read(4)  # skip the magic_number\n",
    "        N = unpack('>I', labels.read(4))[0]\n",
    "    \n",
    "        if number_of_images != N:\n",
    "            raise Exception('number of labels did not match the number of images')\n",
    "            \n",
    "        # Get the data\n",
    "        x = np.zeros((N, rows, cols), dtype=np.uint8)  # Initialize numpy array\n",
    "        y = np.zeros((N, 1), dtype=np.uint8)  # Initialize numpy array\n",
    "        \n",
    "        for i in range(N):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"i: %i\" % i)\n",
    "            x[i] = \n",
    "            [[unpack('>B', images.read(1))[0] for unused_col in range(cols)]  \n",
    "             for unused_row in range(rows) ]\n",
    "            \n",
    "            y[i] = unpack('>B', labels.read(1))[0]\n",
    "            \n",
    "        data = {'x': x, 'y': y, 'rows': rows, 'cols': cols}\n",
    "        pickle.dump(data, open(pn, \"wb\"))\n",
    "    return data\n",
    "\n",
    "def reduce_data(factor, data):\n",
    "    x = data['x'] #image data\n",
    "    rows = data['rows']\n",
    "    cols = data['cols']\n",
    "    \n",
    "    if rows % factor or cols % factor:\n",
    "        print('Data reduction failed to due that data size not divisible by factor')\n",
    "        return data\n",
    "    \n",
    "    x_new = []\n",
    "    count = 0;\n",
    "    for image in x:        \n",
    "        count = count + 1;\n",
    "        if count % 100:\n",
    "            print('Reducing image #%i' % count)\n",
    "        #if count == 5:\n",
    "        #    break\n",
    "        i_new = zeros((int(rows/factor), int(cols/factor)))\n",
    "        for r in range(0, rows, factor):\n",
    "            for c in range(0,cols, factor):\n",
    "                min_r = max(r-(factor-1),0)\n",
    "                max_r = min(r+(factor-1),rows-1)\n",
    "                min_c = max(c-(factor-1),0)\n",
    "                max_c = min(c+(factor-1),cols-1)\n",
    "                \n",
    "                #sum over pixels that should be averaged\n",
    "                sum_sub = 0;\n",
    "                for i in image[min_r:max_r]:\n",
    "                    sum_sub = sum_sub + sum(xx for xx in i[min_c:max_c])\n",
    "                #normalize\n",
    "                nbrElements = (max_c-min_c)*(max_r-min_r)\n",
    "                sum_sub = sum_sub/(nbrElements)\n",
    "                i_new[int(r/factor), int(c/factor)] = sum_sub #save in new array\n",
    "    \n",
    "        x_new.append(i_new)\n",
    "    \n",
    "    data['x'] = x_new\n",
    "    data['rows'] = rows/factor\n",
    "    data['cols'] = cols/factor\n",
    "    return data\n",
    "\n",
    "def savePickle(data, picklename):\n",
    "    \n",
    "    picklename = '%s.pickle' % picklename\n",
    "    \n",
    "    path = Path(os.path.dirname(__file__) )\n",
    "    path = path / MNIST_data_path    \n",
    "    \n",
    "    pn = path / picklename # full path for pickle file\n",
    "    pickle.dump(data, open(pn, \"wb\"))\n",
    "    \n",
    "    \n",
    "#looks throught the current path for files starting with <network_file> \n",
    "#and returns the most trained version:\n",
    "# this is evaluated by the size of the last number in the file name. \n",
    "#Thus file_196Neurons_10000 is considered newer than  file_196Neurons_5000\n",
    "def findLatestVersion(network_file):\n",
    "    nf_versions = \n",
    "    [n for n in glob.glob(network_file+'*') if os.path.isfile(n)] # finds all files \n",
    "                                                                  # starting with \n",
    "                                                                  # <network_file>\n",
    "    if not nf_versions:\n",
    "        return [], 0\n",
    "    nbrs = [int(findall('[0-9]+',v)[-1]) for v in nf_versions]\n",
    "    return nf_versions[nbrs.index(max(nbrs))], max(nbrs) #returns the filename \n",
    "                                                         #corresponding to the latest version\n",
    "                                                         #and the images trained\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
